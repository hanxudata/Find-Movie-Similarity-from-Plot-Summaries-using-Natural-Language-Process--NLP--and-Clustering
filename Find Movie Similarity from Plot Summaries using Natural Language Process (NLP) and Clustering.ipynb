{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xp3LTq59E8UK"
   },
   "source": [
    "## Movie titles from IMDB and plot summary from Wiki\n",
    "https://www.imdb.com/list/ls055592025/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1552771527088,
     "user": {
      "displayName": "Arthur M",
      "photoUrl": "",
      "userId": "16377123886564016720"
     },
     "user_tz": 420
    },
    "id": "OjdBV8gGE8UQ",
    "outputId": "beec5da5-c4e7-4065-83a5-fe9665d13df9"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wiGJ0f_gE8UV"
   },
   "outputs": [],
   "source": [
    "titles = open('title_list.txt').read().split('\\n')\n",
    "titles = titles[:100]\n",
    "\n",
    "summary_wiki = open('summary_list_wiki.txt').read().split('\\n BREAKS HERE')\n",
    "summary_wiki = summary_wiki[:100]\n",
    "\n",
    "summary_imdb = open('summary_list_imdb.txt').read().split('\\n BREAKS HERE')\n",
    "summary_imdb = summary_imdb[:100]\n",
    "\n",
    "#Combine imdb and wiki to get full synoposes for the top 100 movies. \n",
    "summary = []\n",
    "for i in range(len(summary_wiki)):\n",
    "    item = summary_wiki[i] + summary_imdb[i]\n",
    "    summary.append(item)\n",
    "    \n",
    "ranks = range(len(titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iQ4KGnVeE8UX"
   },
   "source": [
    "## Tokenizing and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11182,
     "status": "ok",
     "timestamp": 1552770992326,
     "user": {
      "displayName": "Arthur M",
      "photoUrl": "",
      "userId": "16377123886564016720"
     },
     "user_tz": 420
    },
    "id": "3gSwiUBRE8UY",
    "outputId": "7786ec1e-1b1c-4ede-a95e-880084e0ae11"
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e50130X8E8Uc"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def tokenization_and_stemming(text):\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent) if word not in stopwords]\n",
    "\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "def tokenization(text):\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent) if word not in stopwords]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WtDXMCeME8Uh"
   },
   "source": [
    "Use our defined functions to analyze (i.e. tokenize, stem) our synoposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNtXZ3RlE8Ui"
   },
   "outputs": [],
   "source": [
    "docs_stemmed = []\n",
    "docs_tokenized = []\n",
    "for i in summary:\n",
    "    tokenized_and_stemmed_results = tokenization_and_stemming(i)\n",
    "    docs_stemmed.extend(tokenized_and_stemmed_results)\n",
    "    \n",
    "    tokenized_results = tokenization(i)\n",
    "    docs_tokenized.extend(tokenized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angeles\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from stemmed words to original tokenized words for result interpretation.\n",
    "vocab_frame_dict = {docs_stemmed[x]:docs_tokenized[x] for x in range(len(docs_stemmed))}\n",
    "print (vocab_frame_dict['angel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kj7JZxnpE8Uk"
   },
   "source": [
    "Create a mapping from stemmed words to original tokenized words for result interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "QAWdFqL5E8Uo"
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43940,
     "status": "ok",
     "timestamp": 1552771025155,
     "user": {
      "displayName": "Arthur M",
      "photoUrl": "",
      "userId": "16377123886564016720"
     },
     "user_tz": 420
    },
    "id": "k-XH7R4pE8Up",
    "outputId": "854cd09b-26e5-477b-efa5-697ab6696f0d"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_model = TfidfVectorizer(max_df=0.8, max_features=2000,\n",
    "                                 min_df=0, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenization_and_stemming, ngram_range=(1,3))\n",
    "\n",
    "tfidf_matrix = tfidf_model.fit_transform(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lLdKk6n-E8Uw"
   },
   "outputs": [],
   "source": [
    "tf_selected_words = tfidf_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1hPhgwSeE8U4"
   },
   "source": [
    "## Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43864,
     "status": "ok",
     "timestamp": 1552771025167,
     "user": {
      "displayName": "Arthur M",
      "photoUrl": "",
      "userId": "16377123886564016720"
     },
     "user_tz": 420
    },
    "id": "NI1CN6m6E8U5",
    "outputId": "ba9be51c-9463-474e-bdeb-0bf471e84f51",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.01597512 0.0195209  ... 0.02250815 0.02263374 0.04419743]\n",
      " [0.01597512 1.         0.03149342 ... 0.01242353 0.01330407 0.01937118]\n",
      " [0.0195209  0.03149342 1.         ... 0.01612811 0.0124787  0.04164716]\n",
      " ...\n",
      " [0.02250815 0.01242353 0.01612811 ... 1.         0.03166906 0.04620866]\n",
      " [0.02263374 0.01330407 0.0124787  ... 0.03166906 1.         0.01976279]\n",
      " [0.04419743 0.01937118 0.04164716 ... 0.04620866 0.01976279 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_matrix = cosine_similarity(tfidf_matrix)\n",
    "print (cos_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEcwtws5E8U8"
   },
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LJQ5i3IE8U9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGs4aIIME8U_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Raging Bull</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Casablanca</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>The Wizard of Oz</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                            title  cluster\n",
       "4     0                    The Godfather        4\n",
       "1     1         The Shawshank Redemption        1\n",
       "1     2                 Schindler's List        1\n",
       "2     3                      Raging Bull        2\n",
       "0     4                       Casablanca        0\n",
       "1     5  One Flew Over the Cuckoo's Nest        1\n",
       "1     6               Gone with the Wind        1\n",
       "2     7                     Citizen Kane        2\n",
       "4     8                 The Wizard of Oz        4\n",
       "2     9                          Titanic        2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "films = { 'title': titles, 'rank': ranks, 'summary': summary, 'cluster': clusters}\n",
    "frame = pd.DataFrame(films, index = [clusters] , columns = ['rank', 'title', 'cluster'])\n",
    "frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44583,
     "status": "ok",
     "timestamp": 1552771025923,
     "user": {
      "displayName": "Arthur M",
      "photoUrl": "",
      "userId": "16377123886564016720"
     },
     "user_tz": 420
    },
    "id": "Ht1SbbOSE8VE",
    "outputId": "fcfda6c3-cdcc-4fe7-f015-1835c08ed850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of films included in each cluster:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster\n",
       "1       51\n",
       "4       25\n",
       "2       18\n",
       "3        5\n",
       "0        1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Number of films included in each cluster:\")\n",
    "frame['cluster'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45000,
     "status": "error",
     "timestamp": 1552771026355,
     "user": {
      "displayName": "Arthur M",
      "photoUrl": "",
      "userId": "16377123886564016720"
     },
     "user_tz": 420
    },
    "id": "PEk3P4BTE8VI",
    "outputId": "b8c13f39-9c08-48b4-c3e2-7f92554cac78",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document Clustering Result by K-means>\n",
      "Cluster 0 words:rick,laszlo,renault,ilsa,letters,german,\n",
      "Cluster 0 titles (1 movies): \n",
      "Casablanca\n",
      "\n",
      "Cluster 1 words:paul,killing,butch,german,soldiers,alex,\n",
      "Cluster 1 titles (51 movies): \n",
      "The Shawshank Redemption, Schindler's List, One Flew Over the Cuckoo's Nest, Gone with the Wind, Lawrence of Arabia, Psycho, On the Waterfront, Star Wars, E.T. the Extra-Terrestrial, 2001: A Space Odyssey, The Silence of the Lambs, The Bridge on the River Kwai, Apocalypse Now, The Lord of the Rings: The Return of the King, Gladiator, From Here to Eternity, Saving Private Ryan, Unforgiven, Raiders of the Lost Ark, Rocky, A Streetcar Named Desire, Ben-Hur, Doctor Zhivago, Patton, Jaws, Braveheart, Butch Cassidy and the Sundance Kid, Platoon, Dances with Wolves, The Pianist, Goodfellas, The Deer Hunter, All Quiet on the Western Front, The French Connection, The King's Speech, Mr. Smith Goes to Washington, Fargo, The Grapes of Wrath, Shane, The Green Mile, Close Encounters of the Third Kind, Pulp Fiction, The African Queen, Stagecoach, Mutiny on the Bounty, The Maltese Falcon, A Clockwork Orange, Double Indemnity, Rebel Without a Cause, Rear Window, North by Northwest\n",
      "\n",
      "Cluster 2 words:kane,juror,travis,emma,heathcliff,scotty,\n",
      "Cluster 2 titles (18 movies): \n",
      "Raging Bull, Citizen Kane, Titanic, Vertigo, West Side Story, 12 Angry Men, My Fair Lady, High Noon, It Happened One Night, Rain Man, Annie Hall, Out of Africa, Good Will Hunting, Terms of Endearment, The Graduate, American Graffiti, Taxi Driver, Wuthering Heights\n",
      "\n",
      "Cluster 3 words:joe,beale,norma,ratso,sheldrake,fran,\n",
      "Cluster 3 titles (5 movies): \n",
      "Sunset Blvd., Some Like It Hot, The Apartment, Midnight Cowboy, Network\n",
      "\n",
      "Cluster 4 words:george,michael,dorothy,forrestal,gandhi,vito,\n",
      "Cluster 4 titles (25 movies): \n",
      "The Godfather, The Wizard of Oz, The Godfather: Part II, Forrest Gump, The Sound of Music, Chinatown, Singin' in the Rain, It's a Wonderful Life, Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb, Amadeus, Gandhi, The Philadelphia Story, To Kill a Mockingbird, An American in Paris, The Best Years of Our Lives, The Good, the Bad and the Ugly, The Treasure of the Sierra Madre, The Exorcist, City Lights, A Place in the Sun, Tootsie, Giant, Nashville, The Third Man, Yankee Doodle Dandy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"<Document Clustering Result by K-means>\")\n",
    "\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "Cluster_keywords_summary = {}\n",
    "for i in range(num_clusters):\n",
    "    print (\"Cluster \" + str(i) + \" words:\", end='')\n",
    "    Cluster_keywords_summary[i] = []\n",
    "    for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
    "        Cluster_keywords_summary[i].append(vocab_frame_dict[tf_selected_words[ind]])\n",
    "        print (vocab_frame_dict[tf_selected_words[ind]] + \",\", end='')\n",
    "    print ()\n",
    "    \n",
    "    cluster_movies = frame.ix[i]['title'].values.tolist()\n",
    "    print (\"Cluster \" + str(i) + \" titles (\" + str(len(cluster_movies)) + \" movies): \")\n",
    "    print (\", \".join(cluster_movies))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYOZXL53E8VV"
   },
   "source": [
    "## Topic Modeling - Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBPVbFNFE8VW"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=5, learning_method = 'online')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5YYz__7E8VY"
   },
   "outputs": [],
   "source": [
    "tfidf_matrix_lda = (tfidf_matrix * 100)\n",
    "tfidf_matrix_lda = tfidf_matrix_lda.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIwUNN0ZE8Vb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=5, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(tfidf_matrix_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TukTmm7dE8Vd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2000)\n"
     ]
    }
   ],
   "source": [
    "topic_word = lda.components_\n",
    "print(topic_word.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Hs012V-E8Vg"
   },
   "outputs": [],
   "source": [
    "n_top_words = 7\n",
    "topic_keywords_list = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    lda_topic_words = np.array(tf_selected_words)[np.argsort(topic_dist)][:-n_top_words:-1] \n",
    "    for j in range(len(lda_topic_words)):\n",
    "        lda_topic_words[j] = vocab_frame_dict[lda_topic_words[j]]\n",
    "    topic_keywords_list.append(lda_topic_words.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BuSg4tbSE8Vh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "doc_topic = lda.transform(tfidf_matrix_lda)\n",
    "print (doc_topic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "paiC0DU-E8Vj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document Clustering Result by Latent Dirichlet Allocation>\n",
      "Cluster 2 words: terry, michael, karen, henry, lawrence, vito\n",
      "Cluster 2 titles (20 movies): \n",
      "The Godfather, Lawrence of Arabia, The Godfather: Part II, Vertigo, On the Waterfront, The Silence of the Lambs, Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb, Apocalypse Now, The Lord of the Rings: The Return of the King, An American in Paris, The Treasure of the Sierra Madre, High Noon, Goodfellas, Mr. Smith Goes to Washington, Annie Hall, Out of Africa, Terms of Endearment, Shane, American Graffiti, Mutiny on the Bounty\n",
      "\n",
      "Cluster 4 words: dorothy, maria, juror, andy, munny, kane\n",
      "Cluster 4 titles (18 movies): \n",
      "The Shawshank Redemption, Citizen Kane, The Wizard of Oz, The Sound of Music, West Side Story, E.T. the Extra-Terrestrial, 12 Angry Men, From Here to Eternity, Unforgiven, To Kill a Mockingbird, City Lights, It Happened One Night, A Place in the Sun, Tootsie, Fargo, Pulp Fiction, Stagecoach, Wuthering Heights\n",
      "\n",
      "Cluster 0 words: jake, forrestal, rocky, dunbar, schindler, mcmurphy\n",
      "Cluster 0 titles (20 movies): \n",
      "Schindler's List, Raging Bull, One Flew Over the Cuckoo's Nest, Gone with the Wind, Sunset Blvd., Forrest Gump, Star Wars, Chinatown, The Bridge on the River Kwai, Amadeus, Rocky, The Best Years of Our Lives, My Fair Lady, Jaws, Platoon, Dances with Wolves, The Deer Hunter, Rain Man, Double Indemnity, North by Northwest\n",
      "\n",
      "Cluster 1 words: joe, alex, beale, maximus, rick, gandhi\n",
      "Cluster 1 titles (17 movies): \n",
      "Casablanca, 2001: A Space Odyssey, Singin' in the Rain, Some Like It Hot, Gandhi, Gladiator, Ben-Hur, Doctor Zhivago, The Good, the Bad and the Ugly, Butch Cassidy and the Sundance Kid, Midnight Cowboy, Network, A Clockwork Orange, Rebel Without a Cause, Rear Window, The Third Man, Yankee Doodle Dandy\n",
      "\n",
      "Cluster 3 words: paul, travis, george, rose, german, spade\n",
      "Cluster 3 titles (25 movies): \n",
      "Titanic, Psycho, It's a Wonderful Life, Saving Private Ryan, Raiders of the Lost Ark, A Streetcar Named Desire, The Philadelphia Story, Patton, Braveheart, The Apartment, The Pianist, The Exorcist, All Quiet on the Western Front, The French Connection, The King's Speech, Good Will Hunting, Giant, The Grapes of Wrath, The Green Mile, Close Encounters of the Third Kind, Nashville, The Graduate, The African Queen, The Maltese Falcon, Taxi Driver\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_doc_dict = {}\n",
    "print (\"<Document Clustering Result by Latent Dirichlet Allocation>\")\n",
    "for i in range(len(doc_topic)):\n",
    "    topicID = doc_topic[i].argmax()\n",
    "    if topicID not in topic_doc_dict:\n",
    "        topic_doc_dict[topicID] = [titles[i]]\n",
    "    else:\n",
    "        topic_doc_dict[topicID].append(titles[i])\n",
    "for i in topic_doc_dict:\n",
    "    print (\"Cluster \" + str(i) + \" words: \" + \", \".join(topic_keywords_list[i]))\n",
    "    print (\"Cluster \" + str(i) + \" titles (\" + str(len(topic_doc_dict[i])) + \" movies): \")\n",
    "    print (', '.join(topic_doc_dict[i]))\n",
    "    print ()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Unsupervised Learning Project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
